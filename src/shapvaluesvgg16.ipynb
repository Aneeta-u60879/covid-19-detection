{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Data Reading \n\nimport os\nfrom glob import glob\nfrom PIL import Image\n\n# Data Processing \n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport random\nimport albumentations as A\n\n# Data Analysis\n\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data Modeling & Model Evaluation\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras import Sequential\nfrom tensorflow.python.keras import layers, models\nimport tensorflow as tf\ntf.compat.v1.disable_v2_behavior()\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n##tf.compat.v1.enable_eager_execution(\n#config=None, device_policy=None, execution_mode=None\n#)\n\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, recall_score, accuracy_score, precision_score, f1_score, roc_auc_score\n\n# Grad-CAM\n\nimport tensorflow.keras as keras\nimport matplotlib.cm as cm\n\n#Shap\nimport shap\n\n#Sampling\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling  import RandomUnderSampler ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Gathering","metadata":{}},{"cell_type":"code","source":"levels = ['NORMAL', 'COVID19', 'PNEUMONIA']\ntrain_path = \"../input/chest-xray-covid19-pneumonia/Data/train\"\ntest_path = \"../input/chest-xray-covid19-pneumonia/Data/test\"\ntrain_data_dir = os.path.join(train_path)\ntest_path_dir = os.path.join(test_path)\n\ntrain_data = []\nfor id, level in enumerate(levels):\n    for file in os.listdir(os.path.join(train_data_dir, level)):\n        train_data.append(['{}/{}'.format(level, file), level])\n\ntrain_data = pd.DataFrame(train_data, columns = ['image_file', 'corona_result']) \ntrain_data['path'] = train_path + '/' + train_data['image_file']\n              \ntest_data = []\nfor id, level in enumerate(levels):\n    for file in os.listdir(os.path.join(test_path_dir, level)):\n        test_data.append(['{}/{}'.format(level, file), level])\n        \ntest_data = pd.DataFrame(test_data, columns = ['image_file', 'corona_result'])\ntest_data['path'] = test_path + '/' + test_data['image_file']\n\n\ntrain_data['corona_result'] = train_data['corona_result'].map({'NORMAL': 'NORMAL', 'COVID19': 'COVID19', 'PNEUMONIA': 'PNEUMONIA'})\ntest_data['corona_result'] = test_data['corona_result'].map({'NORMAL': 'NORMAL', 'COVID19': 'COVID19', 'PNEUMONIA': 'PNEUMONIA'})\nsamples = 5144\n\ndata = []\ndata = train_data\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['image'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((75,75))))\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***List for images and their labels + Histogram Equalisation***","metadata":{}},{"cell_type":"code","source":"all_data = []\n\n# Storing images and their labels into a list for further Train Test split\n\nfor i in range(len(data)):\n    image = cv2.imread(data['path'][i])\n    \n    #histogram equalisation\n    image=cv2.equalizeHist(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n    image = np.repeat(image[..., np.newaxis], 3, -1)\n    \n    image = cv2.resize(image, (70, 70)) / 255.0\n    if data['corona_result'][i] == \"COVID19\" :\n        label = 1\n    elif data['corona_result'][i] == \"NORMAL\" :\n        label = 0\n    else:\n        label = 2\n    all_data.append([image, label])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train-Test Split : Without Resampling**","metadata":{}},{"cell_type":"code","source":"x = []\ny = []\n\nfor image, label in all_data:\n    x.append(image)\n    y.append(label)\n\n    \n# Converting to Numpy Array    \nx = np.array(x)\ny = np.array(y)\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)\n\n\nprint(x_train.shape, x_test.shape, x_val.shape, y_train.shape, y_test.shape, y_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train-Test Split : With Oversampling** using SMOTE","metadata":{}},{"cell_type":"code","source":"x = []\ny = []\n\nfor image, label in all_data:\n    x.append(image)\n    y.append(label)\n\n# Converting to Numpy Array    \nx = np.array(x)\ny = np.array(y)\nprint(x.shape)\n\ndataForSmote = x.reshape(5144,70 * 70*3)\nprint(dataForSmote.shape)\n\nsm = SMOTE(random_state=42)\nX_smote, y_smote = sm.fit_resample(dataForSmote, y)\nnew_X = X_smote.reshape(-1,70,70,3)\nprint(new_X.shape)\nprint(y_smote.shape)\n\nunique, counts = np.unique(y_smote, return_counts=True)\nprint(dict(zip(unique, counts)))\n\nx_ovtrain, x_ovtest, y_ovtrain, y_ovtest = train_test_split(new_X, y_smote, test_size = 0.2, random_state = 42)\nx_ovtrain, x_ovval, y_ovtrain, y_ovval = train_test_split(x_ovtrain, y_ovtrain, test_size = 0.1, random_state = 42)\n\n\nprint(x_ovtrain.shape, x_ovtest.shape, x_ovval.shape, y_ovtrain.shape, y_ovtest.shape, y_ovval.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train-Test Split : With Undersampling** using Random Undersampler","metadata":{}},{"cell_type":"code","source":"x = []\ny = []\n\nfor image, label in all_data:\n    x.append(image)\n    y.append(label)\n\n# Converting to Numpy Array    \nx = np.array(x)\ny = np.array(y)\nprint(x.shape)\n\n\ndataForrus = x.reshape(5144,70 * 70 * 3)\n#print(dataForrus.shape)\n\n \nrus = RandomUnderSampler(random_state=42)\nX_rus, y_rus = rus.fit_resample(dataForrus, y)\nnew_X = X_rus.reshape(-1,70,70,3)\nprint(new_X.shape)\n#print(y_rus[14])\n\nunique, counts = np.unique(y_rus, return_counts=True)\nprint(dict(zip(unique, counts)))\n\nx_rustrain, x_rustest, y_rustrain, y_rustest = train_test_split(new_X, y_rus, test_size = 0.2, random_state = 42)\nx_rustrain, x_rusval, y_rustrain, y_rusval = train_test_split(x_rustrain, y_rustrain, test_size = 0.1, random_state = 42)\n\n\nprint(x_rustrain.shape, x_rustest.shape, x_rusval.shape, y_rustrain.shape, y_rustest.shape, y_rusval.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Build VGG16 Model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import models, layers,Model\n\ninput_layer=layers.Input(shape=(70,70,3))\n\nmodel_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_layer=model_vgg16.output\n\nflatten=layers.Flatten()(last_layer)\n\noutput_layer=layers.Dense(3,activation='softmax')(flatten)\n\nmodel_vgg16=models.Model(inputs=input_layer,outputs=output_layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model_vgg16.layers[:-1]:\n    layer.trainable=False\n    \nmodel_vgg16.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compile VGG16 Model**","metadata":{}},{"cell_type":"code","source":"model_vgg16.compile(optimizer = 'adam', \n                    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), \n                    metrics = ['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting without Resampling**","metadata":{}},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n\nmodel_vgg16.fit(x_train,y_train,\n          epochs=15,\n          batch_size=256,\n          validation_data=(x_val,y_val),\n          callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting with Oversampling**","metadata":{}},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n\nhistory = model_vgg16.fit(x_ovtrain, y_ovtrain,\n          epochs=15,\n          batch_size=256,\n          validation_data=(x_ovval, y_ovval),\n          callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitiing with Undersampling**","metadata":{}},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n\nhistory = model_vgg16.fit(x_rustrain, y_rustrain,\n          epochs=15,\n          batch_size=256,\n          validation_data=(x_rusval, y_rusval),\n          callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Model Accuracy and Loss Plots***","metadata":{}},{"cell_type":"code","source":"# Summarize History for Accuracy\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train Accuracy', 'Validation Accuracy'], loc = 'lower right')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summarize History for Loss\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train Loss', 'Validation Loss'], loc = 'upper right')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy Loss Graph\n\npd.DataFrame(history.history).plot()\nplt.title('Model Accuracy/Loss')\nplt.ylabel('Accuracy/Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train Loss', 'Train Accuracy', 'Validation Loss', 'Validation Accuracy'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC_AUC_SCORE**","metadata":{}},{"cell_type":"code","source":"#To obtain RUC AUC Score for without resampling method\n\nyp_test = model_vgg16.predict(x_test)\n\nauc = roc_auc_score(y_test, yp_test,average = 'macro', multi_class=\"ovr\")\nprint('ROC AUC: %f' % auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To obtain RUC AUC Score for Oversampling method\n\nyp_test = model_vgg16.predict(x_ovtest)\n\nauc = roc_auc_score(y_ovtest, yp_test,average = 'macro', multi_class=\"ovr\")\nprint('ROC AUC: %f' % auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To obtain RUC AUC Score for Undersampling method\n\nyp_test = model_vgg16.predict(x_rustest)\n\nauc = roc_auc_score(y_rustest, yp_test,average = 'macro', multi_class=\"ovr\")\nprint('ROC AUC: %f' % auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EVALUATION PARAMETERS**","metadata":{}},{"cell_type":"code","source":"yp_train = model_vgg16.predict(x_train)\nyp_train = np.argmax(yp_train, axis = 1)\n\nyp_val = model_vgg16.predict(x_val)\nyp_val = np.argmax(yp_val, axis = 1)\n\nyp_test = model_vgg16.predict(x_test)\nyp_test = np.argmax(yp_test, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp_train = model_vgg16.predict(x_ovtrain)\nyp_train = np.argmax(yp_train, axis = 1)\n\nyp_val = model_vgg16.predict(x_ovval)\nyp_val = np.argmax(yp_val, axis = 1)\n\nyp_test = model_vgg16.predict(x_ovtest)\nyp_test = np.argmax(yp_test, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp_train = model_vgg16.predict(x_rustrain)\nyp_train = np.argmax(yp_train, axis = 1)\n\nyp_val = model_vgg16.predict(x_rusval)\nyp_val = np.argmax(yp_val, axis = 1)\n\nyp_test = model_vgg16.predict(x_rustest)\nyp_test = np.argmax(yp_test, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluation_parametrics(name, y_train, yp_train, y_val, yp_val, y_test, yp_test):\n    \n    print(\"\\n-----------------------------{}-----------------------------\\n\".format(name))\n    \n    cm_train = confusion_matrix(y_train, yp_train)\n    t1 = ConfusionMatrixDisplay(cm_train)\n    s1 = round((cm_train[0,0]/(cm_train[0,0] + cm_train[0,1])),4)\n    \n    print(\"Classification Report for Train Data\\n\")\n    print(classification_report(y_train, yp_train)) \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Train Data: \", round(recall_score(y_train, yp_train,average='micro'),4))\n    print(\"Specificity on Train Data: \", s1)\n    print(\"Accuracy on Train Data: \", round(accuracy_score(y_train, yp_train),4))\n    print(\"Precision on Train Data: \", round(precision_score(y_train, yp_train,average='micro'),4))\n    print(\"F1 Score on Train Data: \", round(f1_score(y_train, yp_train,average='micro'),4))\n    print(\"--------------------------------------------------------------------------\")\n       \n    cm_val = confusion_matrix(y_val, yp_val)\n    t2 = ConfusionMatrixDisplay(cm_val)\n    s2 = round((cm_val[0,0]/(cm_val[0,0] + cm_val[0,1])),4)\n    \n    print(\"\\nClassification Report for Validation Data\\n\")\n    print(classification_report(y_val, yp_val))   \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Val Data: \", round(recall_score(y_val, yp_val,average='micro'),4))\n    print(\"Specificity on Val Data: \", s2)\n    print(\"Accuracy on Val Data: \", round(accuracy_score(y_val, yp_val),4))\n    print(\"Precision on Val Data: \", round(precision_score(y_val, yp_val,average='micro'),4))\n    print(\"F1 Score on Val Data: \", round(f1_score(y_val, yp_val,average='micro'),4))\n    print(\"--------------------------------------------------------------------------\")\n\n    cm_test = confusion_matrix(y_test, yp_test)\n    t3 = ConfusionMatrixDisplay(cm_test)\n    s3 = round((cm_test[0,0]/(cm_test[0,0] + cm_test[0,1])),4)\n    \n    print(\"\\nClassification Report for Test Data\\n\")\n    print(classification_report(y_test, yp_test))   \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Test Data: \", round(recall_score(y_test, yp_test,average='micro'), 4))\n    print(\"Specificity on Test Data: \", s3)\n    print(\"Accuracy on Test Data: \", round(accuracy_score(y_test, yp_test), 4))\n    print(\"Precision on Test Data: \", round(precision_score(y_test, yp_test,average='micro'), 4))\n    print(\"F1 Score Test Data: \", round(f1_score(y_test, yp_test,average='micro'), 4))\n    print(\"--------------------------------------------------------------------------\")\n    \n    t1.plot()\n    t2.plot()   \n    t3.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Metrics - Without Resampling***","metadata":{}},{"cell_type":"code","source":"evaluation_parametrics(\"VGG16\", y_train, yp_train, y_val, yp_val, y_test, yp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Metrics - With Oversampling***","metadata":{}},{"cell_type":"code","source":"evaluation_parametrics(\"VGG16\", y_ovtrain, yp_train, y_ovval, yp_val, y_ovtest, yp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Metrics - With Undersampling***","metadata":{}},{"cell_type":"code","source":"evaluation_parametrics(\"VGG16\", y_rustrain, yp_train, y_rusval, yp_val, y_rustest, yp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHAP VALUES","metadata":{}},{"cell_type":"markdown","source":"**Predicted values from the model are used to determine SHAP values, labelling multi-class images into different dictionary for computing predictions and then analysing the SHAP value results.**\n\n* y_train, y_test - evaluation parameter for without resampling\n* y_ovtrain, y_ovtest - evaluation parameter for Oversampling\n* y_rustrain, y_rustest - evaluation parameter for Undersampling","metadata":{}},{"cell_type":"code","source":"print(np.where(y_train == 0))\nprint(np.where(y_train == 1))\nprint(np.where(y_train == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_test == 0))\nprint(np.where(y_test == 1))\nprint(np.where(y_test == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_ovtrain == 0))\nprint(np.where(y_ovtrain == 1))\nprint(np.where(y_ovtrain == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_ovtest == 0))\nprint(np.where(y_ovtest == 1))\nprint(np.where(y_ovtest == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_rustrain == 0))\nprint(np.where(y_rustrain == 1))\nprint(np.where(y_rustrain == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_rustest == 0))\nprint(np.where(y_rustest == 1))\nprint(np.where(y_rustest == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels= [\"0\",\"1\",\"2\"]\n# example image for each class\nimages_dict = dict()\nimages_dict[0]= x_train[0]\nimages_dict[1]= x_train[4]\nimages_dict[2]= x_train[2]\n\nimages_dict = dict(sorted(images_dict.items()))\n# example image for each class for test set\nx_test_dict = dict()\nx_test_dict[0]= x_test[4]\nx_test_dict[1]= x_test[19]\nx_test_dict[2]= x_test[0] \n\n# order by class\nx_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\nx_test_each_class = np.asarray(x_test_each_class)\n\n# Compute predictions\npredictions = model_vgg16.predict(x_test_each_class)\npredicted_class = np.argmax(predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels= [\"0\",\"1\",\"2\"]\n# example image for each class\nimages_dict = dict()\nimages_dict[0]= x_ovtrain[0]\nimages_dict[1]= x_ovtrain[1]\nimages_dict[2]= x_ovtrain[2]\n\nimages_dict = dict(sorted(images_dict.items()))\n# example image for each class for test set\nx_test_dict = dict()\nx_test_dict[0]= x_ovtest[12]\nx_test_dict[1]= x_ovtest[15]\nx_test_dict[2]= x_ovtest[10]\n\n# order by class\nx_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\nx_test_each_class = np.asarray(x_test_each_class)\n\n# Compute predictions\npredictions = model_vgg16.predict(x_test_each_class)\npredicted_class = np.argmax(predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels= [\"0\",\"1\",\"2\"]\n# example image for each class\nimages_dict = dict()\nimages_dict[0]= x_rustrain[5]\nimages_dict[1]= x_rustrain[11]\nimages_dict[2]= x_rustrain[0]\n\nimages_dict = dict(sorted(images_dict.items()))\n# example image for each class for test set\nx_test_dict = dict()\nx_test_dict[0]= x_rustest[0]\nx_test_dict[1]= x_rustest[1]\nx_test_dict[2]= x_rustest[2]\n\n# order by class\nx_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\nx_test_each_class = np.asarray(x_test_each_class)\n\n# Compute predictions\npredictions = model_vgg16.predict(x_test_each_class)\npredicted_class = np.argmax(predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate the SHAP values:","metadata":{}},{"cell_type":"code","source":"# select a set of background examples to take an expectation over\n\nbackground = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n\nexplainer = shap.DeepExplainer(model_vgg16, background)\n\nshap_val = explainer.shap_values(x_test_each_class,ranked_outputs=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select a set of background examples to take an expectation over\n\nbackground = x_ovtrain[np.random.choice(x_ovtrain.shape[0], 100, replace=False)]\n\nexplainer = shap.DeepExplainer(model_vgg16, background)\n\nshap_val = explainer.shap_values(x_test_each_class,ranked_outputs=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select a set of background examples to take an expectation over\n\nbackground = x_rustrain[np.random.choice(x_rustrain.shape[0], 100, replace=False)]\n\nexplainer = shap.DeepExplainer(model_vgg16, background)\n\nshap_val = explainer.shap_values(x_test_each_class,ranked_outputs=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot actual and predicted class\ndef plot_actual_predicted(images, pred_classes):\n  fig, axes = plt.subplots(1, 4, figsize=(6, 5))\n  axes = axes.flatten()\n  \n  # plot\n  ax = axes[0]\n  dummy_array = np.array([[[0, 0, 0, 0]]], dtype='uint8')\n  ax.set_title(\"Base reference\")\n  ax.set_axis_off()\n  ax.imshow(dummy_array, interpolation='nearest')\n  # plot image\n  for k,v in images.items():\n    ax = axes[k+1]\n    ax.imshow(v, cmap=plt.cm.binary)\n    ax.set_title(f\"True: %s \\nPredict: %s\" % (class_labels[k], class_labels[pred_classes[k]]))\n    ax.set_axis_off()\n  plt.tight_layout()\n  plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Visualization of the SHAP values using image_plot***\n\nRed pixels represent positive SHAP values that contributed to classifying that image as that particular class.\n\n\nBlue pixels represent negative SHAP values that contributed to not classifying that image as that particular class.","metadata":{}},{"cell_type":"code","source":"plot_actual_predicted(x_test_dict,predicted_class)\nshap.image_plot(shap_val,x_test_each_class)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}