{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Data Reading \n\nimport os\nfrom glob import glob\nfrom PIL import Image\n\n# Data Processing \n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport random\nimport albumentations as A\n\n# Data Analysis\n\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data Modeling & Model Evaluation\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras import Sequential\nfrom tensorflow.python.keras import layers, models\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, recall_score, accuracy_score, precision_score, f1_score, roc_auc_score\n\n# Grad-CAM\n\nimport tensorflow.keras as keras\nimport matplotlib.cm as cm\n\n#Shap\nimport shap\n\n#Sampling\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling  import RandomUnderSampler ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Requirement: Downgrade to tf 2.2 **One Time Run and Restart**","metadata":{}},{"cell_type":"code","source":"pip install --upgrade tensorflow==2.2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Gathering**","metadata":{}},{"cell_type":"code","source":"levels = ['NORMAL', 'COVID19', 'PNEUMONIA']\ntrain_path = \"../input/chest-xray-covid19-pneumonia/Data/train\"\ntest_path = \"../input/chest-xray-covid19-pneumonia/Data/test\"\ntrain_data_dir = os.path.join(train_path)\ntest_path_dir = os.path.join(test_path)\n\ntrain_data = []\nfor id, level in enumerate(levels):\n    for file in os.listdir(os.path.join(train_data_dir, level)):\n        train_data.append(['{}/{}'.format(level, file), level])\n\ntrain_data = pd.DataFrame(train_data, columns = ['image_file', 'corona_result']) \ntrain_data['path'] = train_path + '/' + train_data['image_file']\n              \ntest_data = []\nfor id, level in enumerate(levels):\n    for file in os.listdir(os.path.join(test_path_dir, level)):\n        test_data.append(['{}/{}'.format(level, file), level])\n        \ntest_data = pd.DataFrame(test_data, columns = ['image_file', 'corona_result'])\ntest_data['path'] = test_path + '/' + test_data['image_file']\n\n\ntrain_data['corona_result'] = train_data['corona_result'].map({'NORMAL': 'NORMAL', 'COVID19': 'COVID19', 'PNEUMONIA': 'PNEUMONIA'})\ntest_data['corona_result'] = test_data['corona_result'].map({'NORMAL': 'NORMAL', 'COVID19': 'COVID19', 'PNEUMONIA': 'PNEUMONIA'})\nsamples = 5144\n\ndata = []\ndata = train_data\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['image'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((75,75))))\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***List for images and their labels + Histogram Equalisation***","metadata":{}},{"cell_type":"code","source":"all_data = []\n\n# Storing images and their labels into a list for further Train Test split\n\nfor i in range(len(data)):\n    image = cv2.imread(data['path'][i])\n    \n    #histogram equalisation\n    image=cv2.equalizeHist(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n    image = np.repeat(image[..., np.newaxis], 3, -1)\n    \n    image = cv2.resize(image, (70, 70)) / 255.0\n    if data['corona_result'][i] == \"COVID19\" :\n        label = 1\n    elif data['corona_result'][i] == \"NORMAL\" :\n        label = 0\n    else:\n        label = 2\n    all_data.append([image, label])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train-Test Split : Without Resampling**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nx = []\ny = []\n\nfor image, label in all_data:\n    x.append(image)\n    y.append(label)\n\n    \n# Converting to Numpy Array    \nx = np.array(x)\ny = np.array(y)\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)\n\n\nprint(x_train.shape, x_test.shape, x_val.shape, y_train.shape, y_test.shape, y_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train-Test Split : With Oversampling** using SMOTE","metadata":{}},{"cell_type":"code","source":"x = []\ny = []\n\nfor image, label in all_data:\n    x.append(image)\n    y.append(label)\n\n# Converting to Numpy Array    \nx = np.array(x)\ny = np.array(y)\nprint(x.shape)\n\ndataForSmote = x.reshape(5144,70 * 70*3)\nprint(dataForSmote.shape)\n\nsm = SMOTE(random_state=42)\nX_smote, y_smote = sm.fit_resample(dataForSmote, y)\nnew_X = X_smote.reshape(-1,70,70,3)\nprint(new_X.shape)\nprint(y_smote.shape)\n\nunique, counts = np.unique(y_smote, return_counts=True)\nprint(dict(zip(unique, counts)))\n\nx_ovtrain, x_ovtest, y_ovtrain, y_ovtest = train_test_split(new_X, y_smote, test_size = 0.2, random_state = 42)\nx_ovtrain, x_ovval, y_ovtrain, y_ovval = train_test_split(x_ovtrain, y_ovtrain, test_size = 0.1, random_state = 42)\n\n\nprint(x_ovtrain.shape, x_ovtest.shape, x_ovval.shape, y_ovtrain.shape, y_ovtest.shape, y_ovval.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train-Test Split : With Undersampling** using Random Undersampler","metadata":{}},{"cell_type":"code","source":"x = []\ny = []\n\nfor image, label in all_data:\n    x.append(image)\n    y.append(label)\n\n# Converting to Numpy Array    \nx = np.array(x)\ny = np.array(y)\nprint(x.shape)\n\n\ndataForrus = x.reshape(5144,70 * 70 * 3)\n#print(dataForrus.shape)\n\n\nrus = RandomUnderSampler(random_state=42)\nX_rus, y_rus = rus.fit_resample(dataForrus, y)\nnew_X = X_rus.reshape(-1,70,70,3)\nprint(new_X.shape)\n#print(y_rus[14])\n\nunique, counts = np.unique(y_rus, return_counts=True)\nprint(dict(zip(unique, counts)))\n\nx_rustrain, x_rustest, y_rustrain, y_rustest = train_test_split(new_X, y_rus, test_size = 0.2, random_state = 42)\nx_rustrain, x_rusval, y_rustrain, y_rusval = train_test_split(x_rustrain, y_rustrain, test_size = 0.1, random_state = 42)\n\nprint(x_rustrain.shape, x_rustest.shape, x_rusval.shape, y_rustrain.shape, y_rustest.shape, y_rusval.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Build and Compile CNN Model**","metadata":{}},{"cell_type":"code","source":"cnn_model = models.Sequential()\ncnn_model.add(layers.Conv2D(filters = 128, kernel_size = (3, 3), input_shape = (70, 70,3 )))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Dropout(0.3))\n\ncnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3)))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Dropout(0.5))\n\ncnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3)))\ncnn_model.add(layers.Flatten())\ncnn_model.add(Dense(units = 16))\ncnn_model.add(layers.Dropout(0.2))\n\ncnn_model.add(layers.Dense(units = 3,  activation = 'softmax'))\n\ncnn_model.compile(optimizer = 'adam', \n           loss = keras.losses.SparseCategoricalCrossentropy(from_logits = False), \n           metrics = ['accuracy'])\n\ncnn_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting without Resampling**","metadata":{}},{"cell_type":"code","source":"es = keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n\n\nhistory = cnn_model.fit(x_train, y_train, \n                        epochs = 50, batch_size = 256,  \n                        validation_data = (x_val, y_val),\n                        callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting with Oversampling**","metadata":{}},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n\n\nhistory = cnn_model.fit(x_ovtrain, y_ovtrain, \n                        epochs = 50, batch_size = 256,  \n                        validation_data = (x_ovval, y_ovval), \n                        callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitiing with Undersampling**","metadata":{}},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n\n\nhistory = cnn_model.fit(x_rustrain, y_rustrain, \n                        epochs = 50, batch_size = 256,  \n                        validation_data = (x_rusval, y_rusval), \n                        callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To obtain RUC AUC Score for without resampling method\n\nyp_test = cnn_model.predict(x_test)\n\nauc = roc_auc_score(y_test, yp_test, average = 'macro', multi_class='ovo',max_fpr=None).mean()\nprint('ROC AUC SCORE: %f' % auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To obtain RUC AUC Score for Oversampling method\n\nyp_test = cnn_model.predict(x_ovtest)\n\nauc = roc_auc_score(y_ovtest, yp_test,average = 'macro', multi_class=\"ovr\")\nprint('ROC AUC: %f' % auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To obtain RUC AUC Score for Undersampling method\n\nyp_test = cnn_model.predict(x_rustest)\n\nauc = roc_auc_score(y_rustest, yp_test,average = 'macro', multi_class=\"ovr\")\nprint('ROC AUC: %f' % auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Metrics Requirements**","metadata":{}},{"cell_type":"code","source":"yp_train = cnn_model.predict(x_train)\nyp_train = np.argmax(yp_train, axis = 1)\n\nyp_val = cnn_model.predict(x_val)\nyp_val = np.argmax(yp_val, axis = 1)\n\nyp_test = cnn_model.predict(x_test)\nyp_test = np.argmax(yp_test, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp_train = cnn_model.predict(x_ovtrain)\nyp_train = np.argmax(yp_train, axis = 1)\n\nyp_val = cnn_model.predict(x_ovval)\nyp_val = np.argmax(yp_val, axis = 1)\n\nyp_test = cnn_model.predict(x_ovtest)\nyp_test = np.argmax(yp_test, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp_train = cnn_model.predict(x_rustrain)\nyp_train = np.argmax(yp_train, axis = 1)\n\nyp_val = cnn_model.predict(x_rusval)\nyp_val = np.argmax(yp_val, axis = 1)\n\nyp_test = cnn_model.predict(x_rustest)\nyp_test = np.argmax(yp_test, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluation_parametrics(name, y_train, yp_train, y_val, yp_val, y_test, yp_test):\n    \n    print(\"\\n-----------------------------{}-----------------------------\\n\".format(name))\n    \n    cm_train = confusion_matrix(y_train, yp_train)\n    t1 = ConfusionMatrixDisplay(cm_train)\n    s1 = round((cm_train[0,0]/(cm_train[0,0] + cm_train[0,1])),4)\n    \n    print(\"Classification Report for Train Data\\n\")\n    print(classification_report(y_train, yp_train)) \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Train Data: \", round(recall_score(y_train, yp_train,average='micro'),4))\n    print(\"Specificity on Train Data: \", s1)\n    print(\"Accuracy on Train Data: \", round(accuracy_score(y_train, yp_train),4))\n    print(\"Precision on Train Data: \", round(precision_score(y_train, yp_train,average='micro'),4))\n    print(\"F1 Score on Train Data: \", round(f1_score(y_train, yp_train,average='micro'),4))\n    print(\"--------------------------------------------------------------------------\")\n       \n    cm_val = confusion_matrix(y_val, yp_val)\n    t2 = ConfusionMatrixDisplay(cm_val)\n    s2 = round((cm_val[0,0]/(cm_val[0,0] + cm_val[0,1])),4)\n    \n    print(\"\\nClassification Report for Validation Data\\n\")\n    print(classification_report(y_val, yp_val))   \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Val Data: \", round(recall_score(y_val, yp_val,average='micro'),4))\n    print(\"Specificity on Val Data: \", s2)\n    print(\"Accuracy on Val Data: \", round(accuracy_score(y_val, yp_val),4))\n    print(\"Precision on Val Data: \", round(precision_score(y_val, yp_val,average='micro'),4))\n    print(\"F1 Score on Val Data: \", round(f1_score(y_val, yp_val,average='micro'),4))\n    print(\"--------------------------------------------------------------------------\")\n\n    cm_test = confusion_matrix(y_test, yp_test)\n    t3 = ConfusionMatrixDisplay(cm_test)\n    s3 = round((cm_test[0,0]/(cm_test[0,0] + cm_test[0,1])),4)\n    \n    print(\"\\nClassification Report for Test Data\\n\")\n    print(classification_report(y_test, yp_test))   \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Test Data: \", round(recall_score(y_test, yp_test,average='micro'), 4))\n    print(\"Specificity on Test Data: \", s3)\n    print(\"Accuracy on Test Data: \", round(accuracy_score(y_test, yp_test), 4))\n    print(\"Precision on Test Data: \", round(precision_score(y_test, yp_test,average='micro'), 4))\n    print(\"F1 Score Test Data: \", round(f1_score(y_test, yp_test,average='micro'), 4))\n    print(\"--------------------------------------------------------------------------\")\n    \n    t1.plot()\n    t2.plot()   \n    t3.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Metrics - Without Resampling***","metadata":{}},{"cell_type":"code","source":"evaluation_parametrics(\"Convolution Neural Network\", y_train, yp_train, y_val, yp_val, y_test, yp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Metrics - With Oversampling***","metadata":{}},{"cell_type":"code","source":"evaluation_parametrics(\"Convolution Neural Network\", y_ovtrain, yp_train, y_ovval, yp_val, y_ovtest, yp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Metrics - With Undersampling***","metadata":{}},{"cell_type":"code","source":"evaluation_parametrics(\"Convolution Neural Network\", y_rustrain, yp_train, y_rusval, yp_val, y_rustest, yp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predicting the result by giving random image samples** ","metadata":{}},{"cell_type":"code","source":"model_builder = keras.applications.xception.Xception\nimg_size = (299, 299)\npreprocess_input = keras.applications.xception.preprocess_input\ndecode_predictions = keras.applications.xception.decode_predictions\nimag = []\n\nlast_conv_layer_name = \"block14_sepconv2_act\"\n\n# Reading 2 Covid & 2 Normal & 2 Pneumonia Images for Grad-Cam Analysis\n\nimg_path = [\"../input/chest-xray-covid19-pneumonia/Data/test/COVID19/COVID19(465).jpg\",\n            \"../input/chest-xray-covid19-pneumonia/Data/test/COVID19/COVID19(466).jpg\",\n            \"../input/chest-xray-covid19-pneumonia/Data/test/NORMAL/NORMAL(1285).jpg\",\n           \"../input/chest-xray-covid19-pneumonia/Data/test/NORMAL/NORMAL(1287).jpg\",\n           \"../input/chest-xray-covid19-pneumonia/Data/test/PNEUMONIA/PNEUMONIA(3425).jpg\",\n           \"../input/chest-xray-covid19-pneumonia/Data/test/PNEUMONIA/PNEUMONIA(3429).jpg\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To Get Image into numpy array\n\ndef get_img_array(img_path, size):\n    img = keras.preprocessing.image.load_img(img_path, target_size = size) \n    array = keras.preprocessing.image.img_to_array(img) \n    array = np.expand_dims(array, axis = 0)\n    return array\n\n# Top create heatmaps for the samples\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index = None):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_noncovid_heatmap = []\n\nfor i in img_path:\n    img_array = preprocess_input(get_img_array(i, size = img_size))\n    model = model_builder(weights = \"imagenet\")\n    model.layers[-1].activation = None\n    preds = model.predict(img_array)\n    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n    covid_noncovid_heatmap.append(heatmap)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in img_path:\n    z_img = cv2.imread(i)\n    z_img = cv2.resize(z_img, (70, 70)) / 255.0\n    z_img = z_img.reshape(1, z_img.shape[0], z_img.shape[1], z_img.shape[2])\n    \n    z = cnn_model.predict(z_img)\n    z = np.argmax(z, axis = 1)\n    print(\"Image\", img_path.index(i) + 1, \":\", z)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SHAP VALUES**","metadata":{}},{"cell_type":"markdown","source":"**Predicted values from the model are used to determine SHAP values, labelling multi-class images into different dictionary for computing predictions and then analysing the SHAP value results.**\n\n* y_train, y_test - evaluation parameter for without resampling\n* y_ovtrain, y_ovtest - evaluation parameter for Oversampling\n* y_rustrain, y_rustest - evaluation parameter for Undersampling","metadata":{}},{"cell_type":"code","source":"print(np.where(y_train == 0))\nprint(np.where(y_train == 1))\nprint(np.where(y_train == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_test == 0))\nprint(np.where(y_test == 1))\nprint(np.where(y_test == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_ovtrain == 0))\nprint(np.where(y_ovtrain == 1))\nprint(np.where(y_ovtrain == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_ovtest == 0))\nprint(np.where(y_ovtest == 1))\nprint(np.where(y_ovtest == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_rustrain == 0))\nprint(np.where(y_rustrain == 1))\nprint(np.where(y_rustrain == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(y_rustest == 0))\nprint(np.where(y_rustest == 1))\nprint(np.where(y_rustest == 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels= [\"0\",\"1\",\"2\"]\n# example image for each class\nimages_dict = dict()\nimages_dict[0]= x_train[0]\nimages_dict[1]= x_train[4]\nimages_dict[2]= x_train[2]\n\nimages_dict = dict(sorted(images_dict.items()))\n\n# example image for each class for test set\nx_test_dict = dict()\nx_test_dict[0]= x_test[4]\nx_test_dict[1]= x_test[19]\nx_test_dict[2]= x_test[0]\n\n# order by class\nx_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\nx_test_each_class = np.asarray(x_test_each_class)\n\n# Compute predictions\npredictions = cnn_model.predict(x_test_each_class)\npredicted_class = np.argmax(predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels= [\"0\",\"1\",\"2\"]\n# example image for each class\nimages_dict = dict()\nimages_dict[0]= x_ovtrain[0]\nimages_dict[1]= x_ovtrain[7377]\nimages_dict[2]= x_ovtrain[2]\n\nimages_dict = dict(sorted(images_dict.items()))\n# example image for each class for test set\nx_test_dict = dict()\nx_test_dict[0]= x_ovtest[12]\nx_test_dict[1]= x_ovtest[15]\nx_test_dict[2]= x_ovtest[10]\n\n\n# order by class\nx_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\nx_test_each_class = np.asarray(x_test_each_class)\n\n# Compute predictions\npredictions = cnn_model.predict(x_test_each_class)\npredicted_class = np.argmax(predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels= [\"0\",\"1\",\"2\"]\n# example image for each class\nimages_dict = dict()\nimages_dict[0]= x_rustrain[5]\nimages_dict[1]= x_rustrain[11]\nimages_dict[2]= x_rustrain[0]\n\nimages_dict = dict(sorted(images_dict.items()))\n# example image for each class for test set\nx_test_dict = dict()\nx_test_dict[0]= x_rustest[0]\nx_test_dict[1]= x_rustest[1]\nx_test_dict[2]= x_rustest[272]\n\n# order by class\nx_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\nx_test_each_class = np.asarray(x_test_each_class)\n\n# Compute predictions\npredictions = cnn_model.predict(x_test_each_class)\npredicted_class = np.argmax(predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Generate the SHAP values:**","metadata":{}},{"cell_type":"code","source":"# select a set of background examples to take an expectation over\n\nbackground = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n\nexplainer = shap.DeepExplainer(cnn_model, background)\n\nshap_val = explainer.shap_values(x_test_each_class,ranked_outputs=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select a set of background examples to take an expectation over\n\nbackground = x_ovtrain[np.random.choice(x_ovtrain.shape[0], 100, replace=False)]\n\nexplainer = shap.DeepExplainer(cnn_model, background)\n\nshap_val = explainer.shap_values(x_test_each_class,ranked_outputs=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select a set of background examples to take an expectation over\n\nbackground = x_rustrain[np.random.choice(x_rustrain.shape[0], 100, replace=False)]\n\nexplainer = shap.DeepExplainer(cnn_model, background)\n\nshap_val = explainer.shap_values(x_test_each_class,ranked_outputs=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot actual and predicted class\ndef plot_actual_predicted(images, pred_classes):\n  fig, axes = plt.subplots(1, 4, figsize=(6, 5))\n  axes = axes.flatten()\n  \n  # plot\n  ax = axes[0]\n  dummy_array = np.array([[[0, 0, 0, 0]]], dtype='uint8')\n  ax.set_title(\"Base reference\")\n  ax.set_axis_off()\n  ax.imshow(dummy_array, interpolation='nearest')\n  # plot image\n  for k,v in images.items():\n    ax = axes[k+1]\n    ax.imshow(v, cmap=plt.cm.binary)\n    ax.set_title(f\"True: %s \\nPredict: %s\" % (class_labels[k], class_labels[pred_classes[k]]))\n    ax.set_axis_off()\n  plt.tight_layout()\n  plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Visualization of the SHAP values using image_plot***\n\nRed pixels represent positive SHAP values that contributed to classifying that image as that particular class.\n\n\nBlue pixels represent negative SHAP values that contributed to not classifying that image as that particular class.","metadata":{}},{"cell_type":"code","source":"plot_actual_predicted(x_test_dict,predicted_class)\nshap.image_plot(shap_val,x_test_each_class)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}